{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "my_array=np.array([1,2,3])\n",
    "print(my_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor=tf.convert_to_tensor(my_array,tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.constant([1,2,3],tf.float32)\n",
    "b=tf.constant([4,5,6],tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 7. 9.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1=np.array([[1,2,3],[4,5,6]])\n",
    "arr2=np.array([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=tf.convert_to_tensor(arr1,tf.float64)\n",
    "t2=tf.convert_to_tensor(arr2,tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3=tf.matmul(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(2, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30. 36. 42.]\n",
      " [66. 81. 96.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4=tf.matrix_determinant(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.66133814775094e-16\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(t4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../Machine learning/Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns=[]\n",
    "for key in df.keys():\n",
    "    if key=='Id':\n",
    "        continue\n",
    "    if key=='Species':\n",
    "        continue\n",
    "    feature_columns.append(tf.contrib.layers.feature_column.real_valued_column(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_RealValuedColumn(column_name='SepalLengthCm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='SepalWidthCm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='PetalLengthCm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='PetalWidthCm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1feature_columns=[PL,PW,SL,PW]\n",
    "#2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp06t1c06z\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Rahul\\\\AppData\\\\Local\\\\Temp\\\\tmp06t1c06z', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F84BEAB160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator=tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=[10],n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn():\n",
    "    df=pd.read_csv(\"../Machine Learning/Iris.csv\")\n",
    "    df=df.drop(['Id'],axis=1)\n",
    "    #y=df[\"Species\"]\n",
    "    y=pd.Categorical(df['Species']).codes\n",
    "    print(y)\n",
    "    y=np.array(y,dtype=np.int32)\n",
    "    df=df.drop(['Species'],axis=1)\n",
    "    x=df\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(x,y,test_size=0.2)\n",
    "    \n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       " 18             5.7           3.8            1.7           0.3\n",
       " 57             4.9           2.4            3.3           1.0\n",
       " 132            6.4           2.8            5.6           2.2\n",
       " 127            6.1           3.0            4.9           1.8\n",
       " 40             5.0           3.5            1.3           0.3\n",
       " 100            6.3           3.3            6.0           2.5\n",
       " 96             5.7           2.9            4.2           1.3\n",
       " 62             6.0           2.2            4.0           1.0\n",
       " 146            6.3           2.5            5.0           1.9\n",
       " 41             4.5           2.3            1.3           0.3\n",
       " 90             5.5           2.6            4.4           1.2\n",
       " 111            6.4           2.7            5.3           1.9\n",
       " 145            6.7           3.0            5.2           2.3\n",
       " 51             6.4           3.2            4.5           1.5\n",
       " 135            7.7           3.0            6.1           2.3\n",
       " 22             4.6           3.6            1.0           0.2\n",
       " 102            7.1           3.0            5.9           2.1\n",
       " 29             4.7           3.2            1.6           0.2\n",
       " 12             4.8           3.0            1.4           0.1\n",
       " 0              5.1           3.5            1.4           0.2\n",
       " 130            7.4           2.8            6.1           1.9\n",
       " 60             5.0           2.0            3.5           1.0\n",
       " 27             5.2           3.5            1.5           0.2\n",
       " 55             5.7           2.8            4.5           1.3\n",
       " 70             5.9           3.2            4.8           1.8\n",
       " 103            6.3           2.9            5.6           1.8\n",
       " 115            6.4           3.2            5.3           2.3\n",
       " 121            5.6           2.8            4.9           2.0\n",
       " 39             5.1           3.4            1.5           0.2\n",
       " 101            5.8           2.7            5.1           1.9\n",
       " ..             ...           ...            ...           ...\n",
       " 14             5.8           4.0            1.2           0.2\n",
       " 54             6.5           2.8            4.6           1.5\n",
       " 47             4.6           3.2            1.4           0.2\n",
       " 69             5.6           2.5            3.9           1.1\n",
       " 148            6.2           3.4            5.4           2.3\n",
       " 106            4.9           2.5            4.5           1.7\n",
       " 147            6.5           3.0            5.2           2.0\n",
       " 3              4.6           3.1            1.5           0.2\n",
       " 124            6.7           3.3            5.7           2.1\n",
       " 92             5.8           2.6            4.0           1.2\n",
       " 89             5.5           2.5            4.0           1.3\n",
       " 7              5.0           3.4            1.5           0.2\n",
       " 53             5.5           2.3            4.0           1.3\n",
       " 144            6.7           3.3            5.7           2.5\n",
       " 98             5.1           2.5            3.0           1.1\n",
       " 46             5.1           3.8            1.6           0.2\n",
       " 33             5.5           4.2            1.4           0.2\n",
       " 75             6.6           3.0            4.4           1.4\n",
       " 83             6.0           2.7            5.1           1.6\n",
       " 88             5.6           3.0            4.1           1.3\n",
       " 123            6.3           2.7            4.9           1.8\n",
       " 21             5.1           3.7            1.5           0.4\n",
       " 5              5.4           3.9            1.7           0.4\n",
       " 140            6.7           3.1            5.6           2.4\n",
       " 79             5.7           2.6            3.5           1.0\n",
       " 64             5.6           2.9            3.6           1.3\n",
       " 35             5.0           3.2            1.2           0.2\n",
       " 11             4.8           3.4            1.6           0.2\n",
       " 72             6.3           2.5            4.9           1.5\n",
       " 114            5.8           2.8            5.1           2.4\n",
       " \n",
       " [120 rows x 4 columns],\n",
       "      SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       " 149            5.9           3.0            5.1           1.8\n",
       " 141            6.9           3.1            5.1           2.3\n",
       " 85             6.0           3.4            4.5           1.6\n",
       " 99             5.7           2.8            4.1           1.3\n",
       " 4              5.0           3.6            1.4           0.2\n",
       " 65             6.7           3.1            4.4           1.4\n",
       " 56             6.3           3.3            4.7           1.6\n",
       " 32             5.2           4.1            1.5           0.1\n",
       " 77             6.7           3.0            5.0           1.7\n",
       " 10             5.4           3.7            1.5           0.2\n",
       " 38             4.4           3.0            1.3           0.2\n",
       " 108            6.7           2.5            5.8           1.8\n",
       " 93             5.0           2.3            3.3           1.0\n",
       " 117            7.7           3.8            6.7           2.2\n",
       " 129            7.2           3.0            5.8           1.6\n",
       " 24             4.8           3.4            1.9           0.2\n",
       " 28             5.2           3.4            1.4           0.2\n",
       " 66             5.6           3.0            4.5           1.5\n",
       " 122            7.7           2.8            6.7           2.0\n",
       " 30             4.8           3.1            1.6           0.2\n",
       " 134            6.1           2.6            5.6           1.4\n",
       " 16             5.4           3.9            1.3           0.4\n",
       " 20             5.4           3.4            1.7           0.2\n",
       " 87             6.3           2.3            4.4           1.3\n",
       " 109            7.2           3.6            6.1           2.5\n",
       " 97             6.2           2.9            4.3           1.3\n",
       " 43             5.0           3.5            1.6           0.6\n",
       " 23             5.1           3.3            1.7           0.5\n",
       " 143            6.8           3.2            5.9           2.3\n",
       " 125            7.2           3.2            6.0           1.8,\n",
       " array([0, 1, 2, 2, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1, 2, 0, 2, 0, 0, 0, 2, 1,\n",
       "        0, 1, 1, 2, 2, 2, 0, 2, 0, 0, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 0, 1,\n",
       "        2, 2, 2, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 0, 2, 1, 0, 2, 2, 1,\n",
       "        0, 0, 2, 2, 0, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 1, 0, 2, 2, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 1, 2, 2, 2, 0, 2, 1, 1, 0, 1, 2, 1, 0, 0, 1, 1, 1,\n",
       "        2, 0, 0, 2, 1, 1, 0, 0, 1, 2]),\n",
       " array([2, 2, 1, 1, 0, 1, 1, 0, 1, 0, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 2, 0,\n",
       "        0, 1, 2, 1, 0, 0, 2, 2]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#estimator.train(input_fn=my_input_fn,steps=200)\n",
    "X_TRAIN,X_TEST,Y_TRAIN,Y_TEST=my_input_fn()\n",
    "def my_input_fn_test():\n",
    "    return dict(X_TEST),Y_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator.evaluate(input_fn=my_input_fn,steps=1)\n",
    "def my_train_input_fn():\n",
    "    return dict(X_TRAIN),Y_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp06t1c06z\\model.ckpt-2\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2 into C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp06t1c06z\\model.ckpt.\n",
      "INFO:tensorflow:loss = 137.31711, step = 3\n",
      "INFO:tensorflow:Saving checkpoints for 102 into C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp06t1c06z\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 27.270283.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1f84beab828>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=my_train_input_fn,steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-13-07:57:59\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp06t1c06z\\model.ckpt-102\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-13-07:57:59\n",
      "INFO:tensorflow:Saving dict for global step 102: accuracy = 0.93333334, average_loss = 0.24648617, global_step = 102, loss = 7.394585\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 102: C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp06t1c06z\\model.ckpt-102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.93333334,\n",
       " 'average_loss': 0.24648617,\n",
       " 'loss': 7.394585,\n",
       " 'global_step': 102}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=my_input_fn_test,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../Machine Learning/traintitanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"PassengerId\",\"Fare\",\"Ticket\",\"Name\",\"Cabin\"],axis=1)\n",
    "df=df.join(pd.get_dummies(df['Sex']))\n",
    "df=df.drop([\"Sex\"],axis=1)\n",
    "df=df.join(pd.get_dummies(df['Embarked']))\n",
    "df=df.drop([\"Embarked\"],axis=1)\n",
    "df=df.drop(['female'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['C'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'male', 'Q', 'S'], dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns=[]\n",
    "for key in df.keys():\n",
    "    if key=='Survived':\n",
    "        continue\n",
    "    feature_columns.append(tf.contrib.layers.feature_column.real_valued_column(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_RealValuedColumn(column_name='Pclass', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='Age', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='SibSp', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='Parch', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='male', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='Q', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),\n",
       " _RealValuedColumn(column_name='S', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn1():\n",
    "    df=pd.read_csv(\"../Machine Learning/traintitanic.csv\")\n",
    "    df=df.drop([\"PassengerId\",\"Fare\",\"Ticket\",\"Name\",\"Cabin\"],axis=1)\n",
    "    df=df.join(pd.get_dummies(df['Sex']))\n",
    "    df=df.drop([\"Sex\"],axis=1)\n",
    "    df=df.join(pd.get_dummies(df['Embarked']))\n",
    "    df=df.drop([\"Embarked\"],axis=1)\n",
    "    df=df.drop(['female'],axis=1)\n",
    "    df=df.drop(['C'],axis=1)\n",
    "    df=df.dropna()\n",
    "    y=df[\"Survived\"]\n",
    "    #y=pd.Categorical(df['Species']).codes\n",
    "    #print(y)\n",
    "    y=np.array(y,dtype=np.int32)\n",
    "    df=df.drop(['Survived'],axis=1)\n",
    "    x=df\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(x,y,test_size=0.2)\n",
    "    \n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp8az_4aej\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Rahul\\\\AppData\\\\Local\\\\Temp\\\\tmp8az_4aej', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F84D564CF8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator=tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=[20,20],n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN,X_TEST,Y_TRAIN,Y_TEST=my_input_fn()\n",
    "def my_input_fn_test():\n",
    "    return dict(X_TEST),Y_TEST\n",
    "#estimator.evaluate(input_fn=my_input_fn,steps=1)\n",
    "def my_train_input_fn():\n",
    "    return dict(X_TRAIN),Y_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp8az_4aej\\model.ckpt.\n",
      "INFO:tensorflow:loss = 406.90674, step = 1\n",
      "INFO:tensorflow:global_step/sec: 398.098\n",
      "INFO:tensorflow:loss = 290.92407, step = 101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 594.439\n",
      "INFO:tensorflow:loss = 252.22069, step = 201 (0.168 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp8az_4aej\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 235.32831.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1f84d564dd8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=my_train_input_fn,steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-13-08:40:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp8az_4aej\\model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-13-08:40:25\n",
      "INFO:tensorflow:Saving dict for global step 300: accuracy = 0.7622378, accuracy_baseline = 0.5874126, auc = 0.8304076, auc_precision_recall = 0.7868768, average_loss = 0.51706535, global_step = 300, label/mean = 0.4125874, loss = 73.940346, precision = 0.6923077, prediction/mean = 0.45489678, recall = 0.7627119\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: C:\\Users\\Rahul\\AppData\\Local\\Temp\\tmp8az_4aej\\model.ckpt-300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7622378,\n",
       " 'accuracy_baseline': 0.5874126,\n",
       " 'auc': 0.8304076,\n",
       " 'auc_precision_recall': 0.7868768,\n",
       " 'average_loss': 0.51706535,\n",
       " 'label/mean': 0.4125874,\n",
       " 'loss': 73.940346,\n",
       " 'precision': 0.6923077,\n",
       " 'prediction/mean': 0.45489678,\n",
       " 'recall': 0.7627119,\n",
       " 'global_step': 300}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=my_input_fn_test,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
